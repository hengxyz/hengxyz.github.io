---
permalink: /
title: "Welcome to My Homepage!"
excerpt: "About me"
author_profile: true
redirect_from: 
  - "/wordpress/"
  - "/wordpress/index.html"
---

{% include base_path %}

I’m Zuheng Ming, a tenured assistant professor (Maître de conférences) of computer science with [L2TI](https://www-l2ti.univ-paris13.fr/) of [Institut Galilée](https://galilee.univ-paris13.fr/) in [Université Sorbonne Paris Nord (formerly Université Paris-XIII)](https://www.univ-paris13.fr/). Before, I was  a lecturer (Enseignant-Cheurcheur Contactuel) in the computer science department with [L3i](https://l3i.univ-larochelle.fr/) at [La Rochelle University](https://www.univ-larochelle.fr/en/). I have  been also a postdoc in the [L3i](https://l3i.univ-larochelle.fr/) Lab of La Rochelle University supervised by [Pr. Jean-Christophe Burie](https://scholar.google.fr/citations?user=nDsQHAQAAAAJ&hl=en) and [Pr. Muriel Visani](https://pageperso.univ-lr.fr/mvisani/). I spent also one year and a half as a postdoc in the [LaBRI](https://www.labri.fr/) of the [University of Bordeaux](https://www.u-bordeaux.com/) supervised by [Pr. Aurélie Bugeau](https://www.iufrance.fr/les-membres-de-liuf/membre/2370-aurelie-bugeau.html). I obtained my Ph.D. degree from the [Gipsa-lab](http://www.gipsa-lab.grenoble-inp.fr/index.php) of the [University of Grenoble Alpes](https://www.univ-grenoble-alpes.fr/) supervised by [Pr. Gang Feng](https://www.grenoble-inp.fr/fr/personnel/m-feng-gang) and [Dr. Denis Beautemps](https://scholar.google.fr/citations?user=IUBvHCcAAAAJ&hl=fr). Prior to coming to France, I obtained the MSc degree from [Beijing Institute of Technology](https://english.bit.edu.cn/) and BSc degree from [Hunan University](http://www-en.hnu.edu.cn/index.htm) in China.

## Research Interests: 
- computer vision, multimodal learning, deep learning 
- document analysis, biometric, remote sensing, medical image processing

<!---
My research interests span in computer vision, multimodal learning and deep learning as well as its applications.  
- Applications: Biometrics (face anti-spoofing, face recognition, face detection); document images classifications; interdisciplinary applications of deep learning
- Methods: Supervised/Self-supervised deep learning methods (Transformers, CNNs, ...); Multimodal learning (language-vision), Multi-task learning and Metric learning; 
- Data: Natural images, heterogeneous data (text, visiaul images, 3D depth images, caricatures)  
--->

## *News :* 
- <img alt="Clips" src="/images/new2.gif" align="center" width="40"> <font size=3><em><strong> [06/2025]</strong>: Our paper <a href=" ">  LCMF: Lightweight Cross-Modality Mambaformer for Embodied Robotics VQA </a> </em>  has been accepted by <strong><a href="https://ieee-swc-2025.github.io/uic/">The 22nd IEEE International Conference on Ubiquitous Intelligence and Computing (2025).</a></strong><span style="color:red">Congratulations <em><strong>Zeyi Kang! </strong></em></font>
- <img alt="Clips" src="/images/new2.gif" align="center" width="40"> <font size=3><em><strong> [06/2025]</strong>: Our paper <a href=" ">  M3ET: Efficient Vision-Language Learning for Robotics Based on Multimodal Mamba-Enhanced Transformer </a> </em>  has been accepted by <strong><a href="https://ieee-swc-2025.github.io/uic/">The 22nd IEEE International Conference on Ubiquitous Intelligence and Computing (2025). </a></strong><span style="color:red">Congratulations <em><strong>Yanxin Zhang ! </strong></em></font>
- <font size=3><em><strong>[03/2025]</strong>: I will be serving as Technical Committee of <strong><a href="https://iccv.thecvf.com/">ICCV 2025</a></strong>!</em></font>
- <img alt="Clips" src="/images/new2.gif" align="center" width="40"> <font size=3><em><strong>[02/2025]</strong>: I will be serving as <em><strong>Area Chair</strong></em> of <strong><a href="https://2025.ieeeicip.org/">ICIP 2025</a></strong>!</em></font>
- <font size=3><em><strong>[02/2025]</strong>: I will be serving as Technical Committee of <strong><a href="https://www.icdar2025.com/">ICDAR 2025</a></strong>!</em></font>
- <font size=3><em><strong>[12/2024]</strong>: I will be serving as Technical Committee of <strong><a href="https://cvpr.thecvf.com/">CVPR 2025</a></strong>!</em></font>
- <font size=3><em><strong> [11/2024]</strong>: Our paper <a href="https://arxiv.org/abs/2309.05756">  GlobalDoc: A Cross-Modal Vision-Language Framework for Real-World Document Image Retrieval and Classification </a> </em>  has been accepted by <strong><a href="https://wacv2025.thecvf.com/">WACV 2025 !</a></strong></font>
- <font size=3><em><strong> [06/2024]</strong>: Our paper <a href="https://arxiv.org/pdf/2310.13876">  MULTIMODAL TRANSFORMER USING CROSS-CHANNEL ATTENTION FOR OBJECT DETECTION IN REMOTE SENSING IMAGES </a> </em>  has been accepted by <strong><a href="https://2024.ieeeicip.org/">ICIP 2024</a></strong><span style="color:red">(Oral presentation)</span>! Congratulations <em><strong>Bissmella Bahaduri ! </strong></em></font>
- <font size=3><em><strong>[05/2024]</strong>: I will be serving as Technical Committee of <strong><a href="https://neurips.cc/">NeurIPS 2024</a></strong>!</em></font>
- <font size=3><em><strong>[02/2024]</strong>: We are organizing the <a href="https://www.euvip2024.org/" style="color:red;"> 12th European Workshop on Visual Information Processing (EUVIP 2024, IEEE) </a></em> which will be held on 8th-11th September 2024, in Geneva, Swissland. Welcome to submit!
- <font size=3><em><strong>[02/2024]</strong>: I will be serving as Program Committee of <strong><a href="https://icdar2024.net/">ICDAR 2024</a></strong>!</em></font>
- <font size=3><em><strong>[01/2024]</strong>: I will be serving as Technical Committee of <strong><a href="https://2024.ieeeicip.org/">ICIP 2024</a></strong>!</em></font>
- <font size=3><em>[05/2023]: I will serve as a session chair at 	
 <a href="https://sifed2023.sciencesconf.org/" style="color:red;"> Symposium International Francophone sur l'Ecrit et le Document (SIFED 2023)! </a></em>
- <font size=3><em>[02/2023]: We are organizing the <a href="https://sites.google.com/view/icip-2023-object-detection/accueil" style="color:red;"> ICIP2023 Challenge Object Detection Under Uncontrolled Acquisition Environment and Scene Context Constraints </a></em> with <a href="https://www.universite-paris-saclay.fr/" style="color:black;"> <strong>University Paris Scalay</strong></a> and <a href="https://www.ntnu.edu/" style="color:black;"> <strong> NTNU </strong></a>! Welcome to submit!
- <font size=3><em> [02/2023]: Our paper of multimodal learning for document image classification <a href="https://arxiv.org/pdf/2205.12029.pdf"> VLCDoC: Vision-Language Contrastive Pre-Training Model for Cross-Modal Document Classification </a></em>  has been accepted by <strong>Pattern Recognition (<em>JCR Q1, IF 8.51</em>)</strong>!</font>
- <font size=3><em>[01/2023]: We are organizing the <a href="https://www.euvip2023.org/" style="color:red;"> 11th European Workshop on Visual Information Processing (EUVIP, IEEE) </a></em> which will be held on 11th-14th September 2023, in Gjøvik, Norway. Welcome to submit!
- <font size=3><em>07/2022: We are organizing a Special Issue <a href="https://www.mdpi.com/journal/electronics/special_issues/RY06T6PGQ0">"Deep Learning Approach for Secure and Trustworthy Biometric System" </a></em> on Electronics. Welcome to submit!
- <font size=3><em>[06/2022]: Our paper <a href="https://arxiv.org/pdf/2203.01562.pdf" title="ViTransPAD"> Video-based Transformer for face anti-spoofing entitled ViTransPAD </a></em> has been accepted in <strong>ICIP2022</strong>!</font>
- <font size=3><em> [05/2022]: Our work <a href="https://arxiv.org/pdf/2205.12029.pdf"> VLCDoC: Vision-Language Contrastive Pre-Training
Model for Cross-Modal Document Classification </a></em>  is submitted to <strong>Pattern Recognition</strong>!</font>
- <font size=3><em>[03/2022]: Our work using firstly <a href="https://arxiv.org/pdf/2203.01562.pdf" title="ViTransPAD"> Video-based Transformer for face anti-spoofing entitled ViTransPAD </a> is </em> online!</font>
- <font size=3><em>[03/2022]: Our paper working on multimodal cross self-attention for document images classification passes to the second round review of <strong>IJCAI-ECAI 2022</strong>.</em></font>
- <font size=3><em>[02/2022]: Our paper entitled "Exploring Multi-Tasking Learning in Document Attribute Classification" is accepted at <strong>Pattern Recognition Lettres</strong>.</em></font>
- <font size=3><em>[01/2022]: I will be serving as Technical Committee of <strong><a href="https://www.icpr2022.com/">ICPR 2022</a></strong>!</em></font>
- <font size=3><em>[01/2022]: I will be serving to organize <strong><a href="https://das2022.univ-lr.fr/">DAS 2022</a></strong>, hope to meet more researchers in La Rochelle, France!</em></font>
- <font size=3><em>[10/2021]: Our paper entitled "MIDV-2020: A Comprehensive Benchmark Dataset for Identity Document Analysis" is accepted at <strong>Jounal of Computer Optics</strong>.</em></font>
- <font size=3><em>[09/2021]: Our paper entitled "EAML: ensemble self-attention-based mutual learning network for document image classification" is accepted at <strong>International Journal on Document Analysis and Recognition </strong>.</em></font>
- <font size=3><em>[08/2021]: We release the new benchmark for Identity Document Analysis: <strong>MIDV-2020!</strong> <a href="http://l3i-share.univ-lr.fr/MIDV2020/midv2020.html" title="MIDV2020">[Download]</a></em>.</font>
- <font size=3><em>[06/2021]: Our paper entitled "Cross-modal photo-caricature face recognition based on dynamic multi-task learning" is accepted at <strong>International Journal on Document Analysis and Recognition </strong>.</em></font>

<!---
- <font size=3><em>[12/2020]: Our paper entitled "A survey on anti-spoofing methods for facial recognition with rgb cameras of generic consumer devices" is accepted at <strong>Journal of Imaging </strong>.</em></font>
#- <font size=3><em>[05/2020]: Our paper entitled "Cross-modal deep networks for document image classification" is accepted at <strong>ICIP 2020</strong>.</em></font>
<!---
## *Current supervising students :* 
**PhD Candidates **


**Master students **
--->
## *Academic Activities :* 
**Guest Editor:**
  
- <font size=3><em>Special Issue <a href="https://www.mdpi.com/journal/electronics/special_issues/RY06T6PGQ0">"Deep Learning Approach for Secure and Trustworthy Biometric System" </a> on MDPI Electronics (IF=2.69)</em></font>  
  
**Organising scientific activities:**
- <font size=3><em><a href="https://www.euvip2024.org/">12th European Workshop on Visual Information Processing (EUVIP 2024, IEEE)</a></em></font>
- <font size=3><em><a href="https://sites.google.com/view/icip-2023-object-detection/accueil">ICIP2023 Challenge Object Detection Under Uncontrolled Acquisition Environment and Scene Context Constraints</a></em></font>
- <font size=3><em><a href="https://www.euvip2023.org/">11th European Workshop on Visual Information Processing (EUVIP 2023, IEEE)</a></em></font>
- <font size=3><em><a href="https://das2022.univ-lr.fr/">15TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS2022)</a></em></font> 
- <font size=3><em><a href="http://www.cicling.org/2019/">20th International Conference on Computational Linguistics and Intelligent Text Processing, 2019]</a></em></font>  

**Invited Conference Reviewer:**
- <font size=3><em>ICCV 2025</em></font>
- <font size=3><em>CVPR 2025</em></font>
- <font size=3><em>ICASSP 2025</em></font>
- <font size=3><em>ICLR 2025</em></font>
- <font size=3><em>NeurIPS 2025</em></font>
- <font size=3><em>DAS 2024</em></font>
- <font size=3><em>ICIP 2024, 2023</em></font>   
- <font size=3><em>ICDAR 2025, 2024, 2019, 2017</em></font>   
- <font size=3><em>ICPR 2022,2020,2018</em></font>   
- <font size=3><em>PRICAI 2022,2021</em></font>   

**Invited Journal Reviewer:**
- <font size=3><em>Nature Machine Intelligence (Springer Nature, IF 18.8, ) </em></font>
- <font size=3><em>IEEE Transactions on Information Forensics and Security (IEEE TIFS, JCR Q1) </em></font>
- <font size=3><em>IEEE Transactions on Multimedia (IEEE TMM, JCR Q1) </em></font>
- <font size=3><em>IEEE Transactions on Circuits and Systems for Video Technology (IEEE TCSVT, JCR Q1) </em></font>
- <font size=3><em>Pattern Recognition (PR, JCR Q1) </em></font>
- <font size=3><em>Neural Networks (NN, JCR Q1) </em></font>
- <font size=3><em>EURASIP Journal on Image and Video Processing(Springer, JCR Q2) </em></font>
- <font size=3><em>Neurocomputing (Springer, JCR Q2)</em></font>
- <font size=3><em>Signal Processing (ELSEVIER, JCR Q2)</em></font>
- <font size=3><em>Computer Vision and Image Understanding (Springer, JCR Q2)</em></font>
- <font size=3><em> International Journal on Document Analysis and Recognition (Springer IJDAR, JCR Q2)</em></font>
- <font size=3><em> Signal Image and Video Processing (Springer, JCR Q4)</em></font>
